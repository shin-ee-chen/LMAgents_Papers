# Language Model Agents Reading List
This repository lists papers on language model agents.

### Contents (Actively Updating)
- [1. Multi-agent Simulations and Collaboration](#1-multi-agent-simulations-and-collaboration)
- [2. Interactive Learning From Human Preferences](#2-interactive-learning-from-human-preferences)
- [3. Planning And Reasoning](#3-planning-and-reasoning)
- [4. Multimodal](#4-multimodal)
- [5. Datasets](#5-datasets)
- [6. Safety](#6-safety)

## 1. Multi-agent Simulations and Collaboration
- LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models, Frisch & Giulianelli 2024: https://arxiv.org/pdf/2402.02896
- Distributed statistical inference in social interaction networks, Zubak et al. 2024: http://escholarship.org/content/qt8km974x4/qt8km974x4_noSplash_33fef96d585f9b7a4a31b0fbae01b009.pdf
- The Wisdom of the Partisan Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents, Chuang et al. 2024: https://arxiv.org/pdf/2311.09665  
- The Emergence of Specialized Roles Within Groups, Goldstone et al. 2024: https://onlinelibrary.wiley.com/doi/pdf/10.1111/tops.12644  
- Simulating opinion dynamics with networks of LLM-based agents Chuang et al. 2024: https://arxiv.org/pdf/2311.09618 
- Interaction structure constrains the emergence of conventions in group communication, Boyce et al. 2024: https://www.pnas.org/doi/10.1073/pnas.2403888121
- Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents, Piatti et al. 2024: https://arxiv.org/pdf/2404.16698
- I Want to Break Free! Anti-Social Behavior and Persuasion Ability of LLMs in Multi-Agent Settings with Social Hierarchy, Campedelli et al. 2024: https://arxiv.org/pdf/2410.07109
- ALYMPICS: LLM Agents Meet Game Theory â€” Exploring Strategic Decision-Making with AI Agents, Mao et al. 2024: https://arxiv.org/pdf/2311.03220
- Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models, Qiu et al. 2024: https://arxiv.org/pdf/2407.12532
- (EMNLP 2023) Theory of Mind for Multi-Agent Collaboration via Large Language Models, Li et al. 2023: https://aclanthology.org/2023.emnlp-main.13/
  
Neurips 2024:
- Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy, Guan et al. 2024: https://arxiv.org/abs/2407.06813
- Reflective Multi-Agent Collaboration based on Large Language Models, Bo et al. 2024: https://openreview.net/pdf?id=wWiAR5mqXq
- Chain of Agents: Large Language Models Collaborating on Long-Context Tasks, Zhang et al. 2024: https://arxiv.org/abs/2406.02818

- (ICML 2024) Improving Factuality and Reasoning in Language Models through Multiagent Debate, Du et al. 2023: https://arxiv.org/abs/2305.14325
- (ICLR 2024) AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors, Chen et al. 2024: https://openreview.net/pdf?id=EHg5GDnyq1
- (ACL 2024) Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View, Zhang et al. 2024: https://arxiv.org/abs/2310.02124 

## 2. Interactive Learning From Human Preferences
- Self-Rewarding Language Models, Yuan et al. 2024: https://arxiv.org/pdf/2401.10020 
- Iterative Reasoning Preference Optimization, Pang et al. 2024: https://arxiv.org/pdf/2404.19733 
- Direct Multi-Turn Preference Optimization for Language Agents, Shi et al. 2024: https://arxiv.org/pdf/2406.14868
- DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback, Khan et al. 2024: https://arxiv.org/pdf/2410.06215
- Reflexion: Language Agents with Verbal Reinforcement Learning, Shinn et al. 2023: https://proceedings.neurips.cc/paper_files/paper/2023/file/1b44b878bb782e6954cd888628510e90-Paper-Conference.pdf
- LLF-Benchmark for Interactive Learning from Language Feedback, Cheng et al. 2023: https://arxiv.org/abs/2312.06853 
- A fine-grained comparison of pragmatic language understanding in humans and language models, Hu et al. 2022: https://aclanthology.org/2023.acl-long.230/

## 3. Planning And Reasoning
- Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface, Hua et al. 2024: https://arxiv.org/abs/2410.00079
Neurips 2024:
- AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning, Wu et al. 2024: https://arxiv.org/abs/2406.11200
- Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration, Wang et al. 2024: https://arxiv.org/abs/2406.01014
- Can Graph Learning Improve Planning in LLM-based Agents?, Wu et al. 2024: https://arxiv.org/abs/2405.19119
- Agent Planning with World Knowledge Model, Qiao et al. 2024: https://arxiv.org/abs/2405.14205


## 4. Multimodal
Neurips 2024:
- (Minecraft) Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks, Xie et al. 2024: https://arxiv.org/abs/2402.04559 
- (CLIP) TransAgent: Transfer Vision-Language Foundation Models with Heterogeneous Agent Collaboration, Guo et al. 2024: https://arxiv.org/abs/2410.12183
- Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning, Zhai et al. 2024: https://arxiv.org/abs/2405.10292
- OmniJARVIS: Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents, Wang et al. 2024: https://arxiv.org/abs/2405.10292
- VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought, Sarch et al. 2024: https://arxiv.org/abs/2406.14596

## 5. Datasets
Neurips 2024:
- AGILE: A Novel Reinforcement Learning Framework of LLM Agents, Feng et al. 2024: https://arxiv.org/abs/2405.14751

## 6. Safety
Neurips 2024:
- Secret Collusion among AI Agents: Multi-Agent Deception via Steganography, Motwani et al. 2024: https://arxiv.org/abs/2402.07510
- AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents, Debenedetti et al. 2024: https://arxiv.org/abs/2406.13352
- Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents, Yang et al. 2024: https://arxiv.org/abs/2402.11208
- AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases, Chen et al. 2024: https://arxiv.org/abs/2407.12784
